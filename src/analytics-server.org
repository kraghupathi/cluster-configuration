#+TITLE:     Analytics Server Role                                                                                                                                    
#+DATE:      2015-07-14 Tuesday                                                                                                                                     
#+PROPERTY: session *scratch*
#+PROPERTY: results output
#+PROPERTY: exports code
#+SETUPFILE: org-templates/level-0.org
#+DESCRIPTION: Analytics Server Implementation Documentation
#+OPTIONS: ^:nil

* Introduction
  This documentation describes the requirements, design and
  implementation of analytics node. 

  The basic idea to build this node is to have all the webserver logs
  and awstats of each lab in one place. So that Analytics service uses
  these logs and serves usage of the labs on vlabs.ac.in web page.
  
* Requirement
  Requirements which are specific to analytics node are defined
  bellow and common requirements are defined in
  [[./common.org][common role]]
** Functional requirements
   1. Collect the web server(apache) logs and awstats logs for all the
      labs deployed on both AWS and IIITH infrastructure that are
      currently live(Production).
   2. Collect web server(apache) logs and awstats logs for all the
      labs that are not live.
      - Not live labs :: 
			 *Example 1*: Logs of the labs that were
                         resuming from deploy container on IIITH
                         infrastructure.
			 *Example 2*: Labs on aws which are stopped.
			 
      - NOTE :: Second(2) requirement is one time job. Once we have
                collected the required logs from non live labs, no
                need to collect logs frequently as first(1)
                requirement.
   3. Allow incoming connections on tcp ports 80 and 443 to accept the
      web requests coming from the local subnet
   4. Allow outgoing connections on tcp ports 80 and 443 for yum. 
   5. Available to the external world through domain name(URL).
** Security requirements
    1. Accept incoming connections on tcp port 22 from reverse proxy
       of aws cluster and iiith infrastructure in order to collect
       the logs using rsync command.
* Design
  This section describes the design to make this node functional, the
  implementation is explained in the following section.
  
   We have two different sources, a reverse proxy on AWS
   cluster(Source 1) and a reverse proxy on the base machines in
   IIIT-H (Source 2). These sources are geographically located in
   different continents and on different network.

   We need a way of transferring the data(statistics, logs) in a
   secure manner to the analytics server where it will be
   processed. We have used =rsync= to transfer, and have setup
   periodic transfer jobs using =cronie= which executes every hour.

   As this task involves collecting data from different sources, like
   a cluster which is managed with configuration management tool
   =Ansible= and another one a manually configured server, data
   collation is also a mix of automation and manual steps.

   It is assumed that source node will push the data to analytics
   node. For these assumptions we need to make changes to the reverse
   proxy model of the cluster and manually configure the reverse proxy
   at IIIT-H. These changes are described in respective node models,
   the gist, however, is this node will receive AWstats, apache log
   files every hour.

*** Re-configuring AWS cluster, for the requirements of analytics node
    - Analytics server configured to accept =rsync= over =TCP=,
      manually copy the public key generated on reverse proxy to
      analytics node
    - Reverse Proxy(Source 1) configured to push the generated
      statistics to =Analytics= server at regular intervals
    - Router cofigured to allow incoming =rsync= connections from
      Source 2(IIIT-H reverse proxy) to Analytics server

*** On BASE
   Here we manually setup:
 - Reverse Proxy(Source 2) configured to push generated statistics to
   =Analytics= server every hour.

   #+BEGIN_EXAMPLE
   [root@http ~]# crontab -l
   #Rsync stats from http container to stats instance on AWS
   @hourly rsync -azR -e "ssh -p 2222" /var/www/awstats/awstats* stats.vlabs.ac.in:/root/base/
   @hourly rsync -azR -e "ssh -p 2222" /var/log/httpd/* stats.vlabs.ac.in:/root/base/
   #+END_EXAMPLE
** Network Diagram
*** Network diagram of analytics node
    The network diagram of analytics node in the cluster is
    represented below, it also shows how the node gets the web server
    logs, AWstats statistics files.
    [[./diagrams/analytics-node.png][Analytics node]]
*** Source file for the diagram
    The source file was prepared using Libreoffice 4.3 and VRT
    extensions.
    [[./diagrams/analytics-node.odg][Download source file]]

* Implementation
** Structure of Scripts

#+BEGIN_EXAMPLE
roles/analytics_server
|-- files
|   `-- analytics_http.conf
|-- handlers
|   `-- main.yaml
|-- tasks
|   `-- main.yaml
`-- templates
    `-- analytics_server_iptables
#+END_EXAMPLE

** Firewall Rules

   In addition to common firewall rules, this node allows incoming TCP
   port 22 connections from reverse proxy, for copying logs from
   reverse proxy.

#+BEGIN_SRC yml -n :tangle roles/analytics_server/templates/analytics_server_iptables :eval no
*filter
:INPUT ACCEPT [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
#Accept loopback connections
-A INPUT -i lo -d 127.0.0.0/8 -j ACCEPT
#Rate limit new connections to 20 new connections per 30 seconds
-A INPUT ! -p udp -m state --state NEW -m recent --name new_limit --set
-A INPUT ! -p udp -m state --state NEW -m recent --name new_limit --rcheck --seconds 30 --hitcount 20 -m limit --limit 2/min -j LOG --log-prefix "new_limit_"
-A INPUT ! -p udp -m state --state NEW -m recent --name ssh_limit --rcheck --seconds 30 --hitcount 20 -j DROP
#Accept ICMP ping requests at limited rate
-A INPUT -p icmp --icmp-type echo-request -m limit --limit 60/minute --limit-burst 120 -j ACCEPT
-A INPUT -p icmp --icmp-type echo-request -m limit --limit 1/minute --limit-burst 2 -j LOG
-A INPUT -p icmp --icmp-type echo-request -j DROP
#Allow ongoing connections
-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
#Allow incoming SSH connections from ansible server IPs.
{% for item in ansible_server_ips  %}
-A INPUT -m state --state NEW -s {{item}} -p tcp -m tcp --dport 22 -j ACCEPT
{% endfor %}
#Allow incoming connections from reverse proxy server on TCP port 22
-A INPUT -m state --state NEW -s {{reverseproxy_ip}} -p tcp -m tcp --dport 22 -j ACCEPT
#Allow TCP port 22 connections from rsnapshot backup server
{% for item in rsnapshot_server_ips %}
-A INPUT -s {{item}} -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT
{% endfor %}
#Allow incoming connections from http container on base on TCP port 22
-A INPUT -m state --state NEW -s {{http_container}} -p tcp -m tcp --dport 22 -j ACCEPT
#Allow incoming NRPE queries for nagios from nagios servers
-A INPUT -m state --state NEW -p tcp -m tcp --dport 5666 -j ACCEPT
#Allow SNMP queries from cacti servers
-A INPUT -p udp -m udp --dport 161 -j ACCEPT
-A INPUT -p udp -m udp --dport 162 -j ACCEPT
#Log all other "blocked_input_" attempts with rate limiting
-A INPUT -m state --state NEW -m limit --limit 2/min -j LOG --log-prefix "blocked_input_"
#Reply with proper ICMP error message and reject the connection
-A INPUT -j REJECT --reject-with icmp-host-prohibited
#Disable packet forwarding
-A FORWARD -j REJECT
#########Output rules############
#Allow outgoing connections to localhost
-A OUTPUT -s 127.0.0.0/8 -o lo -j ACCEPT
#Allow ongoing connections
-A OUTPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
#Allow DNS queries
-A OUTPUT -p udp -m udp --dport 53 -j ACCEPT
#Allow server to send emails.  Required for sending logwatch emails
-A OUTPUT -p tcp -m tcp --dport 25 -j ACCEPT
#Allow server to contact web-servers.  This is must for reverseproxy to be able to forward requests to internal web servers
-A OUTPUT -p tcp -m tcp --dport 80 -j ACCEPT
-A OUTPUT -p tcp -m tcp --dport 443 -j ACCEPT
#Allow outgoing ping requests
-A OUTPUT -p icmp --icmp-type echo-request -j ACCEPT
#Allow outgoing connections to rsyslog server
-A OUTPUT -p udp -m udp --dport 514 -j ACCEPT
#Allow outgoing connections to OSSEC server
-A OUTPUT -p udp -m udp --dport 1514 -j ACCEPT
#Log all other "blocked_output_" attempts
-A OUTPUT -m state --state NEW -m limit --limit 2/min -j LOG --log-prefix "blocked_output_"
#Allow outgoing connections on tcp port 8000 to internal subnet, this is for bandwidthd on router
-A OUTPUT -p tcp -m tcp -d {{router_internal_ip}} --dport 8000 -j ACCEPT
#Reply with proper ICMP error message and reject the connection
-A OUTPUT -j REJECT --reject-with icmp-host-prohibited
COMMIT
#+END_SRC
** Tasks 
   Following playbook has tasks to configure the node
#+BEGIN_SRC yml :tangle roles/analytics_server/tasks/main.yaml :eval no
- name: Configure firewall rules
  template: src=analytics_server_iptables dest=/etc/sysconfig/iptables owner=root group=root mode=0600
  notify:
   - restart iptables

#Copying the RP public key, to allow passwordless rsync of AWstats 
- name: Copy the RP pub key to Analytics server
  authorized_key: user=root key="{{ lookup('file', 'rp_pub_key') }}" state=present

# Install epel-release to get pip, and to install flask
- name: install http,epel-release, python-pip, mod_wsgi
  yum: name={{ item }} state=installed
  with_items:
   - epel-release
   - python-pip
   - mod_wsgi
   - httpd

#Use pip to install Flask, Flask-Cache
- name: install Flask, Flask-Cache using pip
  pip: name={{item}} state=present
  with_items:
   - Flask
   - Flask-Cache

#Copy the WSGI file to http configuration under conf.d/
- name: Copying analytics_http.conf to analytics server
  copy: src=analytics_http.conf dest=/etc/http/conf.d/analytics_http.conf
  notify:
   - restart apache
#+END_SRC

** Handlers
   Restart the services httpd and iptables if there are any changes in
   the configuration files. These handlers are called when associated
   tasks in =tasks/main.yaml= notifies to restart the services.

#+BEGIN_SRC yml :tangle roles/analytics_server/handlers/main.yaml :eval no
---
- name: restart iptables
  service: name=iptables state=restarted

- name: restart apache
  service: name=httpd state=restarted enabled=yes

#+END_SRC

** =apache= configuration for Web server gateway interface(WSGI)

#+BEGIN_SRC yml :tangle roles/analytics_server/files/analytics_http.conf :eval no
WSGIScriptAlias / /var/www/html/analytics/analytics.wsgi
WSGIScriptReloading On
<Directory /var/www/html/analytics>
     Order deny,allow
     Allow from all
 </Directory>
#+END_SRC
** Configuration script for setting up analytics server.

#+BEGIN_SRC yml :tangle analytics_server.yaml :eval no
---
- name: This file configures the analytics server
  hosts: analytics_server
  remote_user: root

  vars:
    host_name: "analytics-server.{{prefix}}vlabs.ac.in"
    
  roles:
    - common
    - analytics_server
    - ossec_client
    - rsyslog_client
    - nagios_client

#+END_SRC
* COMMENT  Provision the analytics node 
** Machine Configuration
   + Operating System: centos-6.6
   + Architecture: x86_64
   + Memory: 256 MB
   + Disk space: 10 GB
   + Interface: venet0
** Steps to manually create a centos container 
   #+BEGIN_SRC 
   vzctl create 16133 --ostemplate centos-6-x86_64-point6 --ipadd 10.4.15.133 --diskspace 10G:15.0G --hostname stats-demo.vlabs.ac.in
   vzctl start 16133
   vzctl set 16133 --nameserver inherit --ram 256M --swap 512M --onboot yes --save
   #+END_SRC
** Export proxy Settings if network uses proxy
   #+BEGIN_SRC 
   export http_proxy="proxy.iiit.ac.in:8080"
   export https_proxy="proxy.iiit.ac.in:8080"
   #+END_SRC    
** Update the System
   In order to have a stable deployment server, it is crucial to keep
   things up-to-date and well maintained.  To ensure that we have the
   latest available versions of default applications, we need to
   update our system.  Run the following command to update your system
   #+BEGIN_SRC 
   sudo yum -y update
   #+END_SRC
** Install virtualenv
   Run the following command to download and install virtualenv using
   pip.  =virtualenv= is a tool to create isolated Python
   environments.
   #+BEGIN_SRC 
   sudo pip install virtualenv
   #+END_SRC
** Install epel For RHEL 6.x and CentOS 6.x (x86_64)
   #+BEGIN_SRC 
   rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm
   #+END_SRC
** Install pip with yum command
   #+BEGIN_SRC 
   yum install -y python-pip
   #+END_SRC
** Install Flask
   Enter the following command to get Flask activated in your
   =virtualenv=
   #+BEGIN_SRC 
    pip install Flask
   #+END_SRC
** Install Flask-Cache
   #+BEGIN_SRC 
   pip install Flask-Cache
   #+END_SRC
** Install wsgi on CentOS using yum
   WSGI(Web Server Gateway Interface) is an interface between a web
   server and the application itself. It exists to ensure a
   standardized way between various servers and applications
   (frameworks) to work with each other, allowing interchangeability
   when necessary (e.g. switching from development to production
   environment).
   #+BEGIN_SRC 
   yum install mod_wsgi
   #+END_SRC

** Create a =.wsgi= file
   To run your application you need a =analytics.wsgi= file.  This
   file contains the code =mod_wsgi= is executing on startup to get
   the application object.  The object called application in that file
   is then used as application.
   #+BEGIN_SRC  python :tangle analytics/analytics.wsgi
   import sys 
   sys.path.insert (0,'/var/www/html/analytics/')
   import logging, sys
   logging.basicConfig(stream=sys.stderr)
   from app import app as application
    #+END_SRC
** Configure the Apache and deploy the service
   Configure Apache to load =mod_wsgi= module and your project in
   VirtualHost Insert the following lines in
   =/etc/httpd/conf/httpd.conf=
   #+BEGIN_SRC 
   WSGIScriptAlias / /var/www/html/analytics/analytics.wsgi
   WSGIScriptReloading On
   <Directory /var/www/html/analytics>
     Order deny,allow
     Allow from all
    </Directory>
   #+END_SRC
** Restart Apache
   #+BEGIN_SRC 
   service httpd restart
   #+END_SRC
** Test the service with end point.
   #+BEGIN_SRC 
   http://10.4.15.133/numberofhits
   #+END_SRC

* Test cases
